<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Slow-Fast Policy Optimization: Reposition-Before-Update for LLM Reasoning.">
  <meta name="keywords" content="LLM Reasoning, Reasoning RL training, GRPO, off policy, LLM">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Slow-Fast Policy Optimization: Reposition-Before-Update for LLM Reasoning</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <script>
    window.MathJax = {
      tex: {
        packages: { "[+]": ["ams"] },           // enable AMS (align, aligned, etc.)
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$','$$'], ['\\[','\\]']]
      },
      svg: { fontCache: 'global' }
    };
  </script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
  

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Slow-Fast Policy Optimization: Reposition-Before-Update for LLM Reasoning</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.isye.gatech.edu/users/ziyan-wang">Ziyan Wang</a><sup>*1</sup>,</span>
            <span class="author-block">
              <a href="https://zkbig.github.io/">Zheng Wang</a><sup>*2</sup>,</span>
            <span class="author-block">
              <span class="author-block">Jie Fu</a><sup>*</sup>,
            </span>
            <span class="author-block">
              <span class="author-block">Xingwei Qu</a>,
            </span>
            <span class="author-block">
              <span class="author-block">Qi Cheng</a>,
            </span>
            <span class="author-block">
              <span class="author-block">Shengpu Tang</a>,
            </span>
            <span class="author-block">
              <a href="https://minjiazhang.github.io/">Minjia Zhang</a><sup>2</sup>
            </span>
            <span class="author-block">
              <a href="https://sites.gatech.edu/xiaoming-huo/">Xiaoming Huo</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup>Equal contribution</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Georgia Institute of Technology,</span>
            <span class="author-block"><sup>2</sup>University of Illinois Urbana-Champaign</span>
          </div>

          <!-- <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div> -->

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="sfpo-pipeline">
  <div class="container is-max-desktop">
    <figure class="pipeline">
      <img src="./static/images/SFPO_pipeline.png" alt="SFPO pipeline overview" style="width:90%;max-width:100%;height:auto;display:block;margin:0 auto;">
      <figcaption class="subtitle has-text-centered">
        SFPO pipeline: fast–reposition–slow policy update.
      </figcaption>
    </figure>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
           Reinforcement learning (RL) has become central to enhancing reasoning in large language models (LLMs). Yet on-policy algorithms such as Group Relative Policy Optimization (GRPO) often suffer in early training: noisy gradients from low-quality rollouts lead to unstable updates and inefficient exploration. We introduce Slow-Fast Policy Optimization (SFPO), a simple yet efficient framework to address the above limitations via decomposing each step into three stages: a short fast trajectory of inner steps on the same batch, a reposition mechanism to control off-policy drift, and a final slow correction. This reposition-before-update design preserves the objective and rollout process unchanged, making SFPO plug-compatible with existing policy-gradient pipelines. Extensive experiments demonstrate that SFPO consistently improves stability, reduces number of rollouts, and accelerates convergence of reasoning RL training. Specifically, it outperforms GRPO by up to 2.80 points in average on math reasoning benchmarks. It also achieves up to 4.93× fewer rollouts and a 4.19× reduction in wall-clock time to match GRPO’s best accuracy.
          </p>
        </div>
      </div>
    </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    
    <!-- Method -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
         <figure class="algorithm">
          <img src="./static/images/SFPO_algorithm.png" alt="SFPO algorithm" style="width:80%;max-width:100%;height:auto;display:block;margin:0 auto;">
        </figure>
        
        <div class="content has-text-justified">
          <h3 class="title is-4">Stage I: Fast Trajectory</h3>
          <p>
            In standard on-policy policy-gradient methods such as GRPO, each step is updated by a single stochastic gradient:
          </p>
          <p>
\[
\begin{align}
\theta^{s+1} = \theta^{s} - \eta \nabla_{\theta} \mathcal{L}(\theta^{s}),
\end{align}
\]
          </p>
          <p>
            where $\nabla_{\theta} \mathcal{L}(\theta^{s})$ is estimated from one batch of rollouts. Such one-shot updates suffer from high variance and often drive the policy in unstable directions, especially during early training. SFPO mitigates this by performing multiple inner updates on the <strong>same</strong> batch or rollouts.
          </p>
          <p>
            Formally, starting from parameters $\theta^{s,0}$ at the beginning of step $s$, we execute a short <strong>fast trajectory</strong> of $K$ inner updates:
          </p>
          <p>
\[
\begin{align}
\theta^{s,k+1} = \theta^{s,k} - \eta \nabla_{\theta} \mathcal{L}(\theta^{s,k}), \qquad k=0,\ldots,K-1.
\end{align}
\]
          </p>
          <p>
            This produces a sequence $\theta^{s,0} \to \theta^{s,1} \to \cdots \to \theta^{s,K}$, where each step refines the gradient direction using the same rollout data.
          </p>

          <h3 class="title is-4">Stage II: Reposition</h3>
          <p>
            While the fast trajectory of Stage&nbsp;I improves stability, it also <strong>changes the nature of the update from on-policy to off-policy</strong>. Since all inner steps $\theta^{s,1},\dots,\theta^{s,K}$ reuse the same rollouts generated at $\theta^{s,0}$, the endpoint $\theta^{s,K}$ no longer corresponds to the distribution that produced those samples. This <strong>distribution mismatch</strong> is a fundamental drawback of off-policy learning, as it biases gradient estimates and can destabilize training.
          </p>
          <p>
            Inspired by Lookahead Optimization, SFPO introduces a <strong>reposition step</strong> that interpolates the fast trajectory back toward its starting point:
          </p>
          <p>
\[
\begin{align}
\tilde{\theta}^{s,K} = \theta^{s,0} + \alpha(\theta^{s,K} - \theta^{s,0}), \qquad \alpha \in [0,1].
\end{align}
\]
          </p>
          <p>
            Here $\alpha$ regulates the degree of off-policy drift: smaller values keep the update close to the original on-policy iterate, while larger values rely more on the fast trajectory at the risk of greater mismatch.
          </p>

          <h3 class="title is-4">Stage III: Slow Correction</h3>
          <p>
            After repositioning, SFPO applies one more (slow) correction step at the interpolated point:
          </p>
          <p>
\[
\begin{align}
\theta^{s+1} = \tilde{\theta}^{s,K} - \eta \nabla_{\theta} \mathcal{L} (\tilde{\theta}^{s,K}).
\end{align}
\]
          </p>
          <p>
            This yields a <strong>predictor—corrector</strong> structure: Stage&nbsp;I produces a stabilized <strong>fast trajectory</strong>, Stage&nbsp;II tempers off-policy drift via <strong>reposition</strong>, and Stage&nbsp;III applies a <strong>slow correction</strong> aligned with the local curvature at the update point.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
